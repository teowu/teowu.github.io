{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "wth-VbMAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Wu Haoning", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=wth-VbMAAAAJ&citpid=13", "affiliation": "Dogtor, working on Multimodal Intelligence", "interests": ["Multimodal", "Video Understanding", "Long-context", "Video Quality Assessment"], "email_domain": "@moonshot.cn", "homepage": "http://teowu.github.io/", "citedby": 2816, "publications": {"wth-VbMAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring Video Quality Assessment on User Generated Contents from Aesthetic and Technical Perspectives", "pub_year": "2023"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:YsMSGLbcyi4C", "num_citations": 239, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11037978258611751775,6650893746759494372", "cites_id": ["11037978258611751775", "6650893746759494372"]}, "wth-VbMAAAAJ:qxL8FJ1GzNcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-align: Teaching LMMs for Visual Scoring via Discrete Text-Defined Levels", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:qxL8FJ1GzNcC", "num_citations": 235, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2101774103586253104,2373643679029913635,15478771933307125365", "cites_id": ["2101774103586253104", "2373643679029913635", "15478771933307125365"]}, "wth-VbMAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FAST-VQA: Efficient End-to-end Video Quality Assessment with Fragment Sampling", "pub_year": "2022"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:IjCSPb-OGe4C", "num_citations": 227, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12307408620730287451", "cites_id": ["12307408620730287451"]}, "wth-VbMAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-bench: A benchmark for general-purpose foundation models on low-level vision", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:8k81kl-MbHgC", "num_citations": 178, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11683847823892452807,3223508715790384066", "cites_id": ["11683847823892452807", "3223508715790384066"]}, "wth-VbMAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Agiqa-3k: An open database for ai-generated image quality assessment", "pub_year": "2023"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:ufrVoPGSRksC", "num_citations": 172, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1590585229497860844,11376504162466552631", "cites_id": ["1590585229497860844", "11376504162466552631"]}, "wth-VbMAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Topiq: A top-down approach from semantics to distortions for image quality assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:hqOjcs7Dif8C", "num_citations": 171, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18123811633217424733", "cites_id": ["18123811633217424733"]}, "wth-VbMAAAAJ:rO6llkc54NcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Longvideobench: A benchmark for long-context interleaved video-language understanding", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:rO6llkc54NcC", "num_citations": 153, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14873073151582490177,10664164195700561112", "cites_id": ["14873073151582490177", "10664164195700561112"]}, "wth-VbMAAAAJ:KlAtU1dfN6UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-Instruct: Improving low-level visual abilities for multi-modality foundation models", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:KlAtU1dfN6UC", "num_citations": 110, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1331342797383495989", "cites_id": ["1331342797383495989"]}, "wth-VbMAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Neighbourhood representative sampling for efficient end-to-end video quality assessment", "pub_year": "2023"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:UeHWp8X0CEIC", "num_citations": 73, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2648619813883764975", "cites_id": ["2648619813883764975"]}, "wth-VbMAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Discovqa: Temporal distortion-content transformers for video quality assessment", "pub_year": "2023"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:W7OEmFMy1HYC", "num_citations": 73, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15790017070906467273", "cites_id": ["15790017070906467273"]}, "wth-VbMAAAAJ:3s1wT3WcHBgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Aria: An open multimodal native mixture-of-experts model", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:3s1wT3WcHBgC", "num_citations": 62, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7267658107749839802", "cites_id": ["7267658107749839802"]}, "wth-VbMAAAAJ:ZeXyd9-uunAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards open-ended visual quality comparison", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:ZeXyd9-uunAC", "num_citations": 62, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7932693708176833645", "cites_id": ["7932693708176833645"]}, "wth-VbMAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Intelligent grimm-open-ended visual storytelling via latent diffusion models", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:_FxGoFyzp5QC", "num_citations": 60, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6638285596773981511", "cites_id": ["6638285596773981511"]}, "wth-VbMAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards Explainable In-the-Wild Video Quality Assessment: A Database and a Language-Prompted Approach", "pub_year": "2023"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:WF5omc3nYNoC", "num_citations": 60, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17274460634978933090", "cites_id": ["17274460634978933090"]}, "wth-VbMAAAAJ:7PzlFSSx8tAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AIM 2020 challenge on real image super-resolution: Methods and results", "pub_year": "2020"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:7PzlFSSx8tAC", "num_citations": 48, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15428865194129181591", "cites_id": ["15428865194129181591"]}, "wth-VbMAAAAJ:QIV2ME_5wuYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Gms-3dqa: Projection-based grid mini-patch sampling for 3d model quality assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:QIV2ME_5wuYC", "num_citations": 47, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5736515303062467116", "cites_id": ["5736515303062467116"]}, "wth-VbMAAAAJ:4DMP91E08xMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Aesbench: An expert benchmark for multimodal large language models on image aesthetics perception", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:4DMP91E08xMC", "num_citations": 46, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9563790654256289698", "cites_id": ["9563790654256289698"]}, "wth-VbMAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring the effectiveness of video perceptual representation in blind video quality assessment", "pub_year": "2022"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:2osOgNQ5qMEC", "num_citations": 43, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14141975823412485834", "cites_id": ["14141975823412485834"]}, "wth-VbMAAAAJ:qUcmZB5y_30C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Subjective-aligned dataset and metric for text-to-video quality assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:qUcmZB5y_30C", "num_citations": 41, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7545731794688327996,15967814667690683856", "cites_id": ["7545731794688327996", "15967814667690683856"]}, "wth-VbMAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Advancing zero-shot digital human quality assessment through text-prompted evaluation", "pub_year": "2025"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:Se3iqnhoufwC", "num_citations": 40, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1566447805493249733,8075571695198555541", "cites_id": ["1566447805493249733", "8075571695198555541"]}, "wth-VbMAAAAJ:mVmsd5A6BfQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards A Better Metric for Text-to-Video Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:mVmsd5A6BfQC", "num_citations": 40, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18276588539501626414", "cites_id": ["18276588539501626414"]}, "wth-VbMAAAAJ:b0M2c_1WBrUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Kimi-vl technical report", "pub_year": "2025"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:b0M2c_1WBrUC", "num_citations": 37, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7327189826770849230,15045540419272305770,783499239337750126", "cites_id": ["7327189826770849230", "15045540419272305770", "783499239337750126"]}, "wth-VbMAAAAJ:L8Ckcad2t8MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-bench: A benchmark for multi-modal foundation models on low-level vision from single images to pairs", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:L8Ckcad2t8MC", "num_citations": 34, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15579030550564871419", "cites_id": ["15579030550564871419"]}, "wth-VbMAAAAJ:e5wmG9Sq2KIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "NTIRE 2024 quality assessment of AI-generated content challenge", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:e5wmG9Sq2KIC", "num_citations": 34, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11572929603447436573", "cites_id": ["11572929603447436573"]}, "wth-VbMAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring opinion-unaware video quality assessment with semantic affinity criterion", "pub_year": "2023"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:Tyk-4Ss8FVUC", "num_citations": 34, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8730286251746622084", "cites_id": ["8730286251746622084"]}, "wth-VbMAAAAJ:isC4tDSrTZIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Boosting image quality assessment through efficient transformer adaptation with local feature enhancement", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:isC4tDSrTZIC", "num_citations": 32, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=699373789304026615", "cites_id": ["699373789304026615"]}, "wth-VbMAAAAJ:HDshCWvjkbEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Aigiqa-20k: A large database for ai-generated image quality assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:HDshCWvjkbEC", "num_citations": 31, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14724390090137181388", "cites_id": ["14724390090137181388"]}, "wth-VbMAAAAJ:dhFuZR0502QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AIM 2020 challenge on image extreme inpainting", "pub_year": "2020"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:dhFuZR0502QC", "num_citations": 30, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10771181164146522237", "cites_id": ["10771181164146522237"]}, "wth-VbMAAAAJ:TFP_iSt0sucC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adaptive image quality assessment via teaching large multimodal model to compare", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:TFP_iSt0sucC", "num_citations": 29, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11519501046734869464", "cites_id": ["11519501046734869464"]}, "wth-VbMAAAAJ:TQgYirikUcIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "NTIRE 2024 challenge on short-form UGC video quality assessment: Methods and results", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:TQgYirikUcIC", "num_citations": 27, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14010671446053919170", "cites_id": ["14010671446053919170"]}, "wth-VbMAAAAJ:M3ejUd6NZC8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-boost: On visual quality assessment ability of low-level multi-modality foundation models", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:M3ejUd6NZC8C", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11275383165513983919", "cites_id": ["11275383165513983919"]}, "wth-VbMAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards transparent deep image aesthetics assessment with tag-based content descriptors", "pub_year": "2023"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:5nxA0vEk-isC", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14516415152932180476", "cites_id": ["14516415152932180476"]}, "wth-VbMAAAAJ:_kc_bZDykSQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring the naturalness of ai-generated images", "pub_year": "2023"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:_kc_bZDykSQC", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5388374132264335227", "cites_id": ["5388374132264335227"]}, "wth-VbMAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "NTIRE 2023 quality assessment of video enhancement challenge", "pub_year": "2023"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:eQOLeE2rZwMC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5271017566461389650", "cites_id": ["5271017566461389650"]}, "wth-VbMAAAAJ:IWHjjKOFINEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Misc: Ultra-low bitrate image semantic compression driven by large multimodal model", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:IWHjjKOFINEC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15910158815344101194", "cites_id": ["15910158815344101194"]}, "wth-VbMAAAAJ:hMod-77fHWUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Deep portrait quality assessment. a NTIRE 2024 challenge survey", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:hMod-77fHWUC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16497614326456388763", "cites_id": ["16497614326456388763"]}, "wth-VbMAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards robust text-prompted semantic criterion for in-the-wild video quality assessment", "pub_year": "2023"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:Y0pCki6q_DkC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2122758968666410196", "cites_id": ["2122758968666410196"]}, "wth-VbMAAAAJ:iH-uZ7U-co4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Enhancing blind video quality assessment with rich quality-aware features", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:iH-uZ7U-co4C", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7528966499354264443", "cites_id": ["7528966499354264443"]}, "wth-VbMAAAAJ:YOwf2qJgpHMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Enhancing diffusion models with text-encoder reinforcement learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:YOwf2qJgpHMC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=725349614054658964", "cites_id": ["725349614054658964"]}, "wth-VbMAAAAJ:RHpTSmoSYBkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lmm-pcqa: Assisting point cloud quality assessment with lmm", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:RHpTSmoSYBkC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9563793592119302859,13593736632062893973", "cites_id": ["9563793592119302859", "13593736632062893973"]}, "wth-VbMAAAAJ:CHSYGLWDkRkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Matchtime: Towards automatic soccer game commentary generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:CHSYGLWDkRkC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7926015864815592109", "cites_id": ["7926015864815592109"]}, "wth-VbMAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Local distortion aware efficient transformer adaptation for image quality assessment", "pub_year": "2023"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:0EnyYjriUFMC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16882692332789430102", "cites_id": ["16882692332789430102"]}, "wth-VbMAAAAJ:GnPB-g6toBAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-ground: Image quality grounding with large multi-modality models", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:GnPB-g6toBAC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16953135405221935530", "cites_id": ["16953135405221935530"]}, "wth-VbMAAAAJ:bEWYMUwI8FkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dual-branch network for portrait image quality assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:bEWYMUwI8FkC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16225747423400282825", "cites_id": ["16225747423400282825"]}, "wth-VbMAAAAJ:1sJd4Hv_s6UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Megafusion: Extend diffusion models towards higher-resolution image generation without further tuning", "pub_year": "2025"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:1sJd4Hv_s6UC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10898202528024316353", "cites_id": ["10898202528024316353"]}, "wth-VbMAAAAJ:pqnbT2bcN3wC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VQA:Visual Question Answering for Video Quality Assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:pqnbT2bcN3wC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14341035754778481431", "cites_id": ["14341035754778481431"]}, "wth-VbMAAAAJ:4JMBOYKVnBMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Light-VQA+: A Video Quality Assessment Model for Exposure Correction with Vision-Language Guidance", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:4JMBOYKVnBMC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1333745488597851025", "cites_id": ["1333745488597851025"]}, "wth-VbMAAAAJ:dshw04ExmUIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards universal soccer video understanding", "pub_year": "2025"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:dshw04ExmUIC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10346314120034561709", "cites_id": ["10346314120034561709"]}, "wth-VbMAAAAJ:a0OBvERweLwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Study of Subjective and Objective Naturalness Assessment of AI-Generated Images", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:a0OBvERweLwC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7249468789167148555", "cites_id": ["7249468789167148555"]}, "wth-VbMAAAAJ:4TOpqqG69KYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Iterative token evaluation and refinement for real-world super-resolution", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:4TOpqqG69KYC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7327240879981755943", "cites_id": ["7327240879981755943"]}, "wth-VbMAAAAJ:RYcK_YlVTxYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mmra: A benchmark for multi-granularity multi-image relational association", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:RYcK_YlVTxYC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3582236336014263594", "cites_id": ["3582236336014263594"]}, "wth-VbMAAAAJ:cFHS6HbyZ2cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Videoautoarena: An automated arena for evaluating large multimodal models in video analysis through user simulation", "pub_year": "2025"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:cFHS6HbyZ2cC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11302657345231375252", "cites_id": ["11302657345231375252"]}, "wth-VbMAAAAJ:2P1L_qKh6hAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "R-Bench: Are your Large Multimodal Model Robust to Real-world Corruptions?", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:2P1L_qKh6hAC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11985100529923433424,501049415724680955", "cites_id": ["11985100529923433424", "501049415724680955"]}, "wth-VbMAAAAJ:aqlVkmm33-oC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-refine: A perceptual quality refiner for ai-generated image", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:aqlVkmm33-oC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9549853461719126765", "cites_id": ["9549853461719126765"]}, "wth-VbMAAAAJ:R3hNpaxXUhUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AIS 2024 challenge on video quality assessment of user-generated content: Methods and results", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:R3hNpaxXUhUC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4834346261128285473", "cites_id": ["4834346261128285473"]}, "wth-VbMAAAAJ:YFjsv_pBGBYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Paps-ovqa: Projection-aware patch sampling for omnidirectional video quality assessment", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:YFjsv_pBGBYC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13216107079083487738", "cites_id": ["13216107079083487738"]}, "wth-VbMAAAAJ:g5m5HwL7SMYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-Modality Multi-Attribute Contrastive Pre-Training for Image Aesthetics Computing", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:g5m5HwL7SMYC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1868023142013582986", "cites_id": ["1868023142013582986"]}, "wth-VbMAAAAJ:_Qo2XoVZTnwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "G-refine: A general quality refiner for text-to-image generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:_Qo2XoVZTnwC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8939972674167105647", "cites_id": ["8939972674167105647"]}, "wth-VbMAAAAJ:k_IJM867U9cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A-bench: Are lmms masters at evaluating ai-generated images?", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:k_IJM867U9cC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1654216067590740339,10223411117036564538", "cites_id": ["1654216067590740339", "10223411117036564538"]}, "wth-VbMAAAAJ:KxtntwgDAa4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MRGen: Diffusion-based Controllable Data Engine for MRI Segmentation towards Unannotated Modalities", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:KxtntwgDAa4C", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9997522475615012301", "cites_id": ["9997522475615012301"]}, "wth-VbMAAAAJ:SeFeTyx0c_EC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LIME: Less Is More for MLLM Evaluation", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:SeFeTyx0c_EC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5971024309286831260", "cites_id": ["5971024309286831260"]}, "wth-VbMAAAAJ:vV6vV6tmYwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lime-m: Less is more for evaluation of mllms", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:vV6vV6tmYwMC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15707269393190607466", "cites_id": ["15707269393190607466"]}, "wth-VbMAAAAJ:lSLTfruPkqcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Explore the hallucination on low-level perception for mllms", "pub_year": "2025"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:lSLTfruPkqcC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14191953269944191825", "cites_id": ["14191953269944191825"]}, "wth-VbMAAAAJ:O3NaXMp0MMsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "T2i-scorer: Quantitative evaluation on text-to-image generation via fine-tuned large multi-modal models", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:O3NaXMp0MMsC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11554666882836879525", "cites_id": ["11554666882836879525"]}, "wth-VbMAAAAJ:xtRiw3GOFMkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-agent system for comprehensive soccer understanding", "pub_year": "2025"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:xtRiw3GOFMkC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3740255338106176586", "cites_id": ["3740255338106176586"]}, "wth-VbMAAAAJ:EUQCXRtRnyEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-Adapt: Adapting LMM for Visual Quality Assessment with Progressive Instruction Tuning", "pub_year": "2025"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:EUQCXRtRnyEC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9232123978948005367", "cites_id": ["9232123978948005367"]}, "wth-VbMAAAAJ:bFI3QPDXJZMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Teaching lmms for image quality scoring and interpreting", "pub_year": "2025"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:bFI3QPDXJZMC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2435785177873578153", "cites_id": ["2435785177873578153"]}, "wth-VbMAAAAJ:35N4QoGY0k4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-Bench-Video: Benchmark the Video Quality Understanding of LMMs", "pub_year": "2025"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:35N4QoGY0k4C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9768818756856748334", "cites_id": ["9768818756856748334"]}, "wth-VbMAAAAJ:HoB7MX3m0LUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MMRA: A Benchmark for Evaluating Multi-Granularity and Multi-Image Relational Association Capabilities in Large Visual Language Models", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:HoB7MX3m0LUC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11982879640771448593", "cites_id": ["11982879640771448593"]}, "wth-VbMAAAAJ:maZDTaKrznsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Optimizing Projection-Based Point Cloud Quality Assessment with Human Preferred Viewpoints Selection", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:maZDTaKrznsC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3829228569111670335", "cites_id": ["3829228569111670335"]}, "wth-VbMAAAAJ:ldfaerwXgEUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "CMC-Bench: Towards a New Paradigm of Visual Signal Compression", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:ldfaerwXgEUC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16860410742694368289", "cites_id": ["16860410742694368289"]}, "wth-VbMAAAAJ:ns9cj8rnVeAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "G-Refine: A General Refiner for Text-to-Image Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:ns9cj8rnVeAC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17547060149145274630", "cites_id": ["17547060149145274630"]}, "wth-VbMAAAAJ:uWQEDVKXjbEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VideoReasonBench: Can MLLMs Perform Vision-Centric Complex Video Reasoning?", "pub_year": "2025"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:uWQEDVKXjbEC", "num_citations": 0}, "wth-VbMAAAAJ:SP6oXDckpogC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Scaling-up Perceptual Video Quality Assessment", "pub_year": "2025"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:SP6oXDckpogC", "num_citations": 0}, "wth-VbMAAAAJ:UxriW0iASnsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SpatialScore: Towards Unified Evaluation for Multimodal Spatial Understanding", "pub_year": "2025"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:UxriW0iASnsC", "num_citations": 0}, "wth-VbMAAAAJ:OU6Ihb5iCvQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Generative Frame Sampler for Long Video Understanding", "pub_year": "2025"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:OU6Ihb5iCvQC", "num_citations": 0}, "wth-VbMAAAAJ:abG-DnoFyZgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ProBench: Judging Multimodal Foundation Models on Open-ended Multi-domain Expert Tasks", "pub_year": "2025"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:abG-DnoFyZgC", "num_citations": 0}, "wth-VbMAAAAJ:_xSYboBqXhAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Image Quality Assessment: From Human to Machine Preference", "pub_year": "2025"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:_xSYboBqXhAC", "num_citations": 0}, "wth-VbMAAAAJ:J_g5lzvAfSwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Blind Video Quality Prediction by Uncovering Human Video Perceptual Representation", "pub_year": "2024"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:J_g5lzvAfSwC", "num_citations": 0}, "wth-VbMAAAAJ:pyW8ca7W8N0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-Adapt: Adapting LMM for Visual Quality Perceiver with Progressive Instruction Tuning"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:pyW8ca7W8N0C", "num_citations": 0}, "wth-VbMAAAAJ:4OULZ7Gr8RgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Q-Instruct"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:4OULZ7Gr8RgC", "num_citations": 0}, "wth-VbMAAAAJ:ZHo1McVdvXMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards Open-ended Visual Quality Comparison Supplementary Material"}, "filled": false, "author_pub_id": "wth-VbMAAAAJ:ZHo1McVdvXMC", "num_citations": 0}}, "citedby5y": 2815, "hindex": 29, "hindex5y": 29, "i10index": 44, "i10index5y": 44, "cites_per_year": {"2020": 22, "2021": 10, "2022": 30, "2023": 195, "2024": 1256, "2025": 1294}, "updated": "2025-07-03 08:12:00.817275"}