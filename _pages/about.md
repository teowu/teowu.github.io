---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

- ğŸ‘‹ Hi, Iâ€™m Teo (Timothy) Wu, Second Year PhD Student in Nanyang Technological University ğŸ‡¸ğŸ‡¬, [Resume](https://github.com/teowu/teowu/blob/master/Resume.pdf)
- ğŸŒ± Iâ€™m currently working on *efficient+explainable* [Video Quality Assessment](https://github.com/QualityAssessment)ğŸ“¹

Star our repos if you are interested!!!
[![Star History Chart](https://api.star-history.com/svg?repos=QualityAssessment/DOVER,QualityAssessment/FAST-VQA-and-FasterVQA&type=Timeline)](https://star-history.com/#QualityAssessment/DOVER&QualityAssessment/FAST-VQA-and-FasterVQA&Timeline)

- See my top Repos:
- - ğŸ¥‡[DOVER](https://github.com/teowu/DOVER) TL,DR: the SOTA NR-VQA method, can predict disentangled aesthetic and technical quality. [Colab demo](https://colab.research.google.com/github/taskswithcode/DOVER/blob/master/TWCDOVER.ipynb) available.
- - ğŸ§°[End-to-End VQA Toolbox (FAST-VQA)](https://github.com/teowu/FAST-VQA-and-FasterVQA) TL, DR: An end-to-end Video Quality Assessment toolbox allowing you to develop your methods; official repo for FAST-VQA [ECCV 2022](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136660528.pdf)!
- ğŸ“« Reach me by e-mail: realtimothyhwu@gmail.com, Twitter: [Twitter](https://twitter.com/HaoningTimothy)
- [Google Scholar](https://scholar.google.com.hk/citations?user=wth-VbMAAAAJ&hl=en-US)


# ğŸ”¥ News
- *2022.11*: &nbsp;ğŸ‰ğŸ‰ DOVER (the state-of-the-art on in-the-wild VQA) released its code, model, demo and preprint paper. 
- *2022.10*: &nbsp;ğŸ‰ğŸ‰ FAST-VQA published on Springer, its extension FasterVQA coming out. 

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2022</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[FAST-VQA: Efficient End-to-end Video Quality Assessment with Fragment Sampling]([https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136660528.pdf))

**Haoning Wu**, Chaofeng Chen, Jingwen Hou, Liang Liao, Annan Wang, Wenxiu Sun, Qiong Yan, Weisi Lin

[**GitHub**](https://github.com/QualityAssessment/FAST-VQA-and-FasterVQA) <strong><span class='show_paper_citations' data='wth-VbMAAAAJ:IjCSPb-OGe4C'></span></strong>
- Consisting of fragments and FANet, the proposed FrAgment Sample Transformer for VQA (FAST-VQA) enables efficient end-to-end deep VQA and learns effective video-quality-related representations. It improves state-of-the-art accuracy by around 10% while reducing 99.5% FLOPs on 1080P high-resolution videos.
</div>
</div>



# ğŸ“– Educations
- *2021.09 - (now)*, PhD Student, S-Lab, Nanyang Technological University, supervised by [Prof. Weisi Lin](https://personal.ntu.edu.sg/wslin/Home.html).
- *2017.09 - 2021.07*, B.S. in Computer Science, EECS, Peking University. 



# ğŸ’» Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
